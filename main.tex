%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Welcome to Overleaf --- just edit your article on the left,
% and we'll compile it for you on the right. If you give 
% someone the link to this page, they can edit at the same
% time. See the help menu above for more info. Enjoy!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% For more detailed article preparation guidelines, please see:
% https://f1000research.com/for-authors/article-guidelines/software-tool-articles and http://f1000research.com/data-preparation

\documentclass[9pt,a4paper]{extarticle}
\usepackage{f1000_styles}
\usepackage[colorlinks=true, linkcolor=darkgray, citecolor=darkgray, urlcolor=blue]{hyperref}

%% Default: numerical citations
% \usepackage[numbers]{natbib}

%% Uncomment this lines for superscript citations instead
% \usepackage[super]{natbib}

%% Uncomment these lines for author-year citations instead
\usepackage[round]{natbib}
\let\cite\citep

%% Get backticks to work
\usepackage{upquote}

%% --------- Code from Knitr -------------------
% \urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}, fontsize=\small}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
%% --------- Code from Knitr -------------------


\begin{document}
\pagestyle{front}

\title{Epidemic curves made easy using the R package \emph{incidence}}

\author[1]{Zhian N. Kamvar\textsuperscript{*}
\footnote{\textsuperscript{*}Corresponding Author: 
Zhian N. Kamvar 
MRC Centre for Outbreak Analysis and Modelling,
Department of Infectious Disease Epidemiology, School of Public Health,
Imperial College London, United Kingdom.
E-mail: zkamvar@gmail.com; ORCiD: 0000-0003-1458-7108}}
\author[2]{Jun Cai}
\author[3]{Juliet R.C. Pulliam}
\author[4]{Jakob Schumacher}
\author[1,5]{Thibaut Jombart
\footnote{Corresponding Author:
Thibaut Jombart
Department of Infectious Disease Epidemiology,
London School of Hygiene and Tropical Medicine, London, UK;
MRC Centre for Outbreak Analysis and Modelling,
Department of Infectious Disease Epidemiology, School of Public Health,
Imperial College London, United Kingdom.
Email: thibautjombart@gmail.com; ORCiD: 0000-0003-2226-8692
}}



\affil[1]{
MRC Centre for Outbreak Analysis and Modelling,
Department of Infectious Disease Epidemiology, School of Public Health,
Imperial College London, United Kingdom.
}
\affil[2]{
Ministry of Education Key Laboratory for Earth
System Modelling, Department of Earth System Science, Tsinghua
University, Beijing 100084, China
}
\affil[3]{
South African DST-NRF Centre of Excellence in Epidemiological Modelling and Analysis (SACEMA), 
Stellenbosch University,
Stellenbosch, South Africa
}
\affil[4]{
Gesundheitsamt Reinickendorf,
Berlin, Germany
}
\affil[5]{
Department of Infectious Disease Epidemiology,
London School of Hygiene and Tropical Medicine, London, UK
}
\maketitle
\thispagestyle{front}

\begin{abstract}

The epidemiological curve (epicurve) is one of the simplest yet most useful tools used by field epidemiologists, modellers, and decision makers for assessing the dynamics of infectious disease epidemics.
Here, we present the free, open-source package \textit{incidence} for the R programming language, which allows users to easily compute, handle, and visualise epicurves from un-aggregated linelist data.
This package was built in accordance with the development guidelines of the R Epidemics Consortium (RECON), which aim to ensure robustness and reliability through extensive automated testing, documentation, and good coding practices. As such, it fills an important gap in the toolbox for outbreak analytics using the R software, and provides a solid building block for further developments in infectious disease modelling. 

\textit{incidence} is available from \url{https://www.repidemicsconsortium.org/incidence}.


\end{abstract}

\section*{Keywords}

epicurve, incidence, epidemics, outbreaks, R

\clearpage
\pagestyle{main}
\section*{Introduction}

Responses to infectious disease epidemics use a growing body of data sources to inform decision making \cite{Fraser2009-vg,WHO_Ebola_Response_Team2014-mr,WHO_Ebola_Response_Team2015-ng,Cori2017-cx}. 
While new data---such as whole genome pathogen sequences---are increasingly useful complements to epidemiological data \cite{Gire2014-pn}, epidemic curves---which describe the number of new cases through time (incidence)---remain the most important source of information, particularly early in an outbreak. 
Specifically epidemic curves(often referred to as `epicurves') represent the number of new cases per time unit based on the date or time of symptom onset.

While conceptually simple, epicurves are useful in many respects. They provide a simple, visual outline of epidemic dynamics, which can be used for assessing the growth or decline of an outbreak \cite{nhan2018severe,fitzgerald2014outbreak,barrett2016ongoing,lanini2014measles,jernberg2015outbreak} and therefore informing intervention measures \cite{Meltzer2014-mn,WHO_Ebola_Response_Team2014-mr,WHO_Ebola_Response_Team2015-ng}.
In addition, epicurves also form the raw material used by a range of modelling techniques for short-term forecasting \cite{Cori2013-fc,Funk2016-ci,Nouvellet2017-an,Viboud2017-bb} as well as in outbreak detection algorithms from syndromic surveillance data \cite{Farrington2003-yv,Unkel2012-po}.

Because of the increasing need to analyse various types of epidemiological data in a single environment using free, transparent and reproducible procedures, the R software \cite{R_Core_Team2017-dg} has been proposed as a platform of choice for epidemic analysis \cite{Jombart2014-fw}.
But despite the existence of packages dedicated to time series analysis \cite{Shumway2010-ci} as well as surveillance data \cite{Hohle2007-vp}, a lightweight and \textit{well-tested} package solely dedicated to building, handling and plotting epidemic curves directly from linelist data (e.g. a spreadsheet where each row represents an individual case) is still lacking.

Here, we introduce \emph{incidence}, an R package developed as part of the toolbox for epidemics analysis of the R Epidemics Consortium (\href{http://www.repidemicsconsortium.org/}{RECON}) which aims to fill this gap.
In this paper, we outline the package's design and illustrate its functionalities using a reproducible worked example.


\section*{Methods}

\subsection*{Package overview}

The philosophy underpinning the development of \emph{incidence} is to `do the basics well'.
The objective of this package is to provide simple, user-friendly and robust tools for computing, manipulating, and plotting epidemic curves, with some additional facilities for basic models of incidence over time.

The general workflow (Figure \ref{fig:workflow}) revolves around a single type of object, formalised as the S3 class \textbf{incidence}.
\textbf{incidence} objects are lists storing separately a matrix of case counts (with dates in rows and groups in columns), dates used as breaks, the time interval used, and an indication of whether incidence is cumulative or not (Figure \ref{fig:workflow}).
The \textbf{incidence} object is obtained by running the function \texttt{incidence()} specifying two inputs: a vector of dates (representing onset of individual cases) and an interval specification. 
The dates can be any type of input representing dates including \textbf{Date} and \textbf{POSIXct} objects, as well as numeric and integer values.
The dates are aggregated into counts based on the user-defined interval representing the number of days for each bin.
The interval can also be defined as a text string of either "week", "month", "quarter", or "year" to represent intervals that can not be defined by a fixed number of days.
For these higher-level intervals, an extra parameter---\texttt{standard}---is available to specify if the interval should start at the standard beginning of the interval (e.g. weeks start on Monday and months start at the first of the month).
\texttt{incidence()} also accepts a \texttt{groups} argument which can be used to obtain stratified incidence.
The basic elements of the \textbf{incidence} object can be obtained by the accessors \texttt{get\_counts()}, \texttt{get\_dates()}, and \texttt{get\_interval()}.

\begin{figure}[h!]
\centering
	\includegraphics[width=0.75\textwidth]{figures/workflow.pdf}
	\caption{\label{fig:workflow}Generalized workflow from incidence object construction to modeling and visualization. 
   	The raw data is depicted in the top left as either a vector of dates for each individual case (typical usage) or a combination of both dates and a matrix of group counts.
    The incidence object is created from these where it checks and validates the timespan and interval between dates. 
    Data subsetting and export is depicted in the upper right. 
    Data visualization is depicted in the lower right.
    Addition of log-linear models is depicted in the lower left.
}
\end{figure}


This package facilitates the manipulation of \textbf{incidence} objects by providing a set of handler functions for the most common tasks.
The function \texttt{subset()} can be used for isolating case data from a specific time window and/or groups, while the {[} operator can be used for a finer control to subset dates and groups using integer, logical or character vectors.
This is accomplished by using the same syntax as for matrix and data.frame objects, i.e. \texttt{x{[i, j]}} where \texttt{x} is the \textbf{incidence} object, and \texttt{i} and \texttt{j} are subsets of dates and groups, respectively.

The function \texttt{pool()} can be used to merge several groups into one, and the function \texttt{cumulate()} will turn incidence data into cumulative incidence.
To maximize interoperability, \textbf{incidence} objects can also be exported to either a matrix using \texttt{get\_counts()} or a data.frame using \texttt{as.data.frame()}, including an option for a `long' format which is readily compatible with \textit{ggplot2} \cite{Wickham2016-pv} for further customization of graphics.

In line with RECON's development guidelines, the \textit{incidence} package is thoroughly tested via automatic tests implemented using \emph{testthat} \cite{Wickham2011-ec}, with an overall coverage nearing 100\% at all times.
We use the continuous integration services \href{https://travis-ci.org/}{travis.ci} and \href{https://ci.appveyor.com/}{appveyor} to ensure that new versions of the code maintain all existing functionalities and give expected results on known datasets, including matching reference graphics tested using the visual regression testing implemented in \emph{vdiffr} \cite{Henry2018-tx}.
Overall, these practices aim to maximise the reliability of the package, and its sustainable development and maintenance over time.

\subsection*{Modeling utilities}

Many different approaches can be used to model, and possibly derive predictions from incidence data \citep[e.g.][]{Wallinga2004-al,Cori2013-fc,Nouvellet2017-an}, and are best implemented in separate packages \citep[e.g.][]{Cori2013-fc}.
Here, we highlight three simple functionalities in \textit{incidence} for estimating parameters via modeling or bootstrap and the two specialized data classes that are used to store the models and parameter estimates.

As a basic model, we implement the simple log-linear regression approach in the function \texttt{fit()}, which can be used to fit exponential increase or decrease of incidence over time by log-transforming case counts and applying a linear regression on these transformed data.
The log-linear regression model is of the form \(log(y) = r \times t + b\) where \(y\) is the incidence, \(r\) is the growth rate, \(t\) is the number of days since the start of the outbreak, and \(b\) is the intercept.
This approach estimates a growth rate \emph{r} (the slope of the regression), which can in turn be used for estimating the doubling or halving time of the epidemic, and with some knowledge of the serial interval, for approximating the reproduction number, \emph{R}\textsubscript{0} \cite{Wallinga2007-hw}.

In the presence of both growing and decreasing phases of an epidemic, the date representing the peak of the epidemic can be estimated. 
In \textit{incidence}, this can be done in two ways. 
The function \texttt{estimate\_peak()} uses multinomial bootstrapping to estimate the peak, assuming that a) reporting is constant over time, b) the total number of cases is known, and c) the bootstrap never samples zero-incidence days. 
This function returns the estimated peak with a confidence interval along with the boostrap estimates.
Alternatively, the function \texttt{fit\_optim\_split()} can be used to detect the optimal turning point of the epidemic and fit two separate models on either side of the peak.
This is done by maximizing the combined mean adjusted $R^2$ value from the two models (Figures \ref{fig:workflow},\ref{fig:incidence-fit}).

The \texttt{fit()} function returns an \textbf{incidence\_fit} object and the \texttt{fit\_optim\_split()} function returns an \textbf{incidence\_fit\_list} object, which is a specialized object designed to contain an unlimited number of (potentially nested) \textbf{incidence\_fit} objects.
While the \textit{incidence} package returns \textbf{incidence\_fit} objects containing log-linear models by default, they can be constructed from any model from which it's possible to extract the growth rate (\emph{r}) and predict incidence along the model.
Both object classes can be plotted separately or added to an existing epicurve using the function \texttt{add\_incidence\_fit()} (Figure \ref{fig:incidence-fit}).

\subsection*{Operation}

The minimal system requirements for successful operation of this package is R version 3.1.

\section*{Use Cases}

Two worked examples are used to demonstrate the functionality and flexibility of the \textit{incidence} package.
The first example illustrates how to compute and manipulate stratified weekly incidence directly from a line-list, while the second example shows how to import pre-computed daily incidence and fit a log-linear model to estimate growth rate (\textit{r}) and doubling time for the growing phase\footnote{Negative values of \textit{r} in incidence are reported as halving times instead of doubling times and decreasing phase instead of growing phase}.

\subsubsection*{Example 1: computing and manipulating stratified weekly incidence}

In this first example, we use the dataset \texttt{ebola\_sim\_clean} in the \href{https://cran.r-project.org/web/packages/outbreaks/index.html}{\textit{outbreaks}} package, which provides a linelist for a fictitious outbreak of Ebola Virus Disease (EVD) that matches some key epidemiological properties (e.g. serial intervals, reproduction numbers) of the West African Ebola outbreak of 2014-2015 \cite{WHO_Ebola_Response_Team2014-mr}.

\textbf{1)  Importing data}

First, we load the dataset \texttt{ebola\_sim\_clean} from the \textit{outbreaks} package.
The dataset contains 5,829 cases of 9 variables, among which the date of symptom onset (\texttt{\$date\_of\_onset}) and the name of the hospital (\texttt{\$hospital}) are used for computing the weekly epicurves stratified by hospitals.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{'outbreaks'}\NormalTok{)}

\NormalTok{dat1 <-}\StringTok{ }\NormalTok{ebola_sim_clean}\OperatorTok{$}\NormalTok{linelist}
\KeywordTok{str}\NormalTok{(dat1, }\DataTypeTok{strict.width =} \StringTok{"cut"}\NormalTok{, }\DataTypeTok{width =} \DecValTok{76}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    5829 obs. of  9 variables:
##  $ case_id                : chr  "d1fafd" "53371b" "f5c3d8" "6c286a" ...
##  $ generation             : int  0 1 1 2 2 0 3 3 2 3 ...
##  $ date_of_infection      : Date, format: NA "2014-04-09" ...
##  $ date_of_onset          : Date, format: "2014-04-07" "2014-04-15" ...
##  $ date_of_hospitalisation: Date, format: "2014-04-17" "2014-04-20" ...
##  $ date_of_outcome        : Date, format: "2014-04-19" NA ...
##  $ outcome                : Factor w/ 2 levels "Death","Recover": NA NA 2 ..
##  $ gender                 : Factor w/ 2 levels "f","m": 1 2 1 1 1 1 1 1 2 ..
##  $ hospital               : Factor w/ 5 levels "Connaught Hospital",..: 2 ..
\end{verbatim}


\textbf{2) Building the incidence object}

The weekly incidence stratified by hospitals is computed by running the function \texttt{incidence()} on the Date variable \texttt{dat1\$date\_of\_onset} with the arguments \texttt{interval = 7} and \texttt{groups = dat1\$hospital}.
The \textbf{incidence} object \texttt{i.7.group} is a list with class of \textbf{incidence} for which several generic methods are implemented, including \texttt{\texttt{print.incidence()}} and \texttt{plot.incidence()}.
Typing \textbf{incidence} object \texttt{i.7.group} implicitly calls the specific function \texttt{print.incidence()} and prints out the summary of the data and its list components.
The 5,829 cases (the total number of cases stored in the \texttt{\$n} component) with dates of symptom onset ranging from 2014-04-07 to 2015-04-27 (spanning from 2014-W15 to 2015-W18 in terms of the ISO 8601 standard for representing weeks) are used for building the \textbf{incidence} object \texttt{i.7.group}.
The \texttt{\$counts} component contains the actual incidence for defined bins, which is a matrix with one column per group.
Here \texttt{\$count} is a matrix with 56 rows and 6 columns as groups by hospital with 6 factor levels are specified.
The bin size in number of days is stored in the \texttt{\$interval} component.
In this example, 7 days suggests that weekly incidence is computed, while by default, daily incidence is computed with the argument \texttt{interval = 1}.
The \texttt{\$dates} component contains all the dates marking the left side of the bins, in the format of the input data (e.g. Date, integer, etc.).
The \texttt{\$timespan} component stores the length of time (in days) for which incidence is computed.
The \texttt{\$cumulative} component is a logical indication whether incidence is cumulative or not.

The generic \texttt{plot()} method for \textbf{incidence} objects calls the specific function \texttt{plot.incidence()}, which makes an incidence barplot using the \textit{ggplot2} package.
Hence, customization of \emph{incidence} plot can benefit from the powerful graphical language from \textit{ggplot2}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{'incidence'}\NormalTok{)}
\KeywordTok{library}\NormalTok{(}\StringTok{'ggplot2'}\NormalTok{)}

\CommentTok{# compute weekly stratified incidence}
\NormalTok{i.7.group <-}\StringTok{ }\KeywordTok{incidence}\NormalTok{(dat1}\OperatorTok{$}\NormalTok{date_of_onset, }\DataTypeTok{interval =}\NormalTok{ 7,} \DataTypeTok{groups =}\NormalTok{ dat1}\OperatorTok{$}\NormalTok{hospital)}
\CommentTok{# print incidence object}
\NormalTok{i.7.group}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <incidence object>
## [5829 cases from days 2014-04-07 to 2015-04-27]
## [5829 cases from ISO weeks 2014-W15 to 2015-W18]
## [6 groups: Connaught Hospital, Military Hospital, other, 
##  Princess Christian Maternity Hospital (PCMH), Rokupa Hospital, NA]
## 
## $counts: matrix with 56 rows and 6 columns
## $n: 5829 cases in total
## $dates: 56 dates marking the left-side of bins
## $interval: 7 days
## $timespan: 386 days
## $cumulative: FALSE
\end{verbatim}



\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# plot incidence object}
\NormalTok{my_theme <-}\StringTok{ }\KeywordTok{theme_bw}\NormalTok{(}\DataTypeTok{base_size =} \DecValTok{12}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{panel.grid.minor =} \KeywordTok{element_blank}\NormalTok{()) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.text.x =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{angle =} \DecValTok{90}\NormalTok{, }\DataTypeTok{hjust =} \DecValTok{1}\NormalTok{, }\DataTypeTok{vjust =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{color =} \StringTok{"black"}\NormalTok{))}

\KeywordTok{plot}\NormalTok{(i.7.group, }\DataTypeTok{border =} \StringTok{"white"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\NormalTok{my_theme }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.8}\NormalTok{, }\FloatTok{0.75}\NormalTok{))}
\end{Highlighting}
\end{Shaded}


\begin{figure}[h!]
\centering
	\includegraphics[width=\textwidth]{figures/incidence-curve-1.pdf}
	\caption{\label{fig:incidence-curve}Weekly epicurves stratified by hospitals for the
simulated outbreak of EVD.}
\end{figure}

Note that when weekly incidence is computed from dates, like in this example, the ISO 8601 standard weeks are used by default with the argument \texttt{standard = TRUE} in the \texttt{incidence()} function.
Under this situation, an extra component of \texttt{\$isoweek} is added to the \textbf{incidence} object \texttt{i.7.group} to store those weeks in the ISO 8601 standard week format ``yyyy-Www'', and the \texttt{\$dates} component stores the corresponding first days of those ISO weeks.
Meanwhile the x-axis tick labels of the weekly \emph{incidence} plot are in the ISO week format ``yyyy-Www'' (see Figure \ref{fig:incidence-curve}) rather than in the date format ``yyyy-mm-dd'' as the argument \texttt{labels\_iso\_week} in the \texttt{plot()} function is by default \texttt{TRUE} when plotting the ISO week-based \textbf{incidence} objects.

\textbf{3) Manipulate the incidence object}

In the above visualisation, it can be difficult to see what the dynamics were in the early stages of the epidemic.
If we want to see the first 18 weeks of the outbreak in the four major hospitals, we can use the {[} operator to subset the rows and columns, which represent weeks and hospitals, respectively, in this particular \textbf{incidence} object.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# plot the first 18 weeks, defined hospitals, and use different colors}
\NormalTok{i.7.sub <-}\StringTok{ }\NormalTok{i.7.group[}\DecValTok{1}\OperatorTok{:}\DecValTok{18}\NormalTok{, }\KeywordTok{grep}\NormalTok{(}\StringTok{"Hospital"}\NormalTok{, }\KeywordTok{group_names}\NormalTok{(1.7.group)}\NormalTok{)]}
\NormalTok{hosp_colors <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"#899DA4"}\NormalTok{, }\StringTok{"#C93312"}\NormalTok{, }\StringTok{"#FAEFD1"}\NormalTok{, }\StringTok{"#DC863B"}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(i.7.sub, }\DataTypeTok{show_cases =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{border =} \StringTok{"black"}\NormalTok{, }\DataTypeTok{color =}\NormalTok{ hosp_colors) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\NormalTok{my_theme }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.35}\NormalTok{, }\FloatTok{0.8}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[h!]
\centering
	\includegraphics[width=0.75\textwidth]{figures/incidence-early-curve-1.pdf}
	\caption{\label{fig:incidence-early-curve}Weekly epicurves stratified by hospitals representing the first eight weeks of
simulated outbreak of EVD.}
\end{figure}

Here, because of the few numbers of cases in the first few weeks, we have also highlighted each case using \texttt{show\_cases = TRUE} (Figure \ref{fig:incidence-early-curve}). We've also used a different color palette to differentiate between the subsetted data and the full data set.

As shown in Figure \ref{fig:incidence-curve}, the missing hospital name (NA) is treated as a separate group, resulting from the default of the argument \texttt{na\_as\_group = TRUE} in the \texttt{incidence()} function. This argument can be set to \texttt{FALSE} to not include data with missing groups in the object.

\subsubsection*{Example 2: importing pre-computed daily incidence and fitting log-linear model}

The datasets \texttt{zika\_girardot\_2015} and \texttt{zika\_sanandres\_2015} used in the second example are also from the \emph{outbreaks} package.
These datasets describe the daily incidence of Zika virus disease (ZVD) in, respectively, Girardot and San Andres Island, Colombia from September 2015 to January 2016.
For details on these datasets, please refer to \citet{Rojas2016-en}.

\textbf{1) Import pre-computed daily incidence}

\texttt{zika\_girardot\_2015} and \texttt{zika\_sanandres\_2015} are data frames with the same variables \texttt{date} and \texttt{cases}.
In order to obtain a more complete picture of the epidemic dynamics of ZVD in Colombia, we merge these two data.frames into a single one, \texttt{dat2}, by variable \texttt{date}.
As \texttt{dat2} is already pre-computed daily incidence rather than a vector of dates such as those in example 1, we can directly convert it into an \textbf{incidence} object grouped by geographical locations, \texttt{i.group}, by using the \texttt{as.incidence()} function.
This shows the flexibility of the \textit{incidence} package in making \textbf{incidence} objects.
Using the \texttt{pool()} function, the daily incidence stratified by locations, \texttt{i.group}, can be collapsed into an incidence object without groups, \texttt{i.pooled}.
The stratified and pooled daily incidence plots of ZVD in Colombia are shown in Figure \ref{fig:incidence-curve2}, from which we can see that the epidemic of ZVD occurred earlier in San Andres Island than in Girardot.


\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# preview datasets}
\KeywordTok{head}\NormalTok{(zika_girardot_2015, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         date cases
## 1 2015-10-19     1
## 2 2015-10-22     2
## 3 2015-10-23     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(zika_sanandres_2015, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         date cases
## 1 2015-09-06     1
## 2 2015-09-07     1
## 3 2015-09-08     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# combine two datasets into one}
\NormalTok{dat2 <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(zika_girardot_2015, zika_sanandres_2015, }\DataTypeTok{by =} \StringTok{"date"}\NormalTok{, }\DataTypeTok{all =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# rename variables}
\KeywordTok{names}\NormalTok{(dat2)[}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{] <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Girardot"}\NormalTok{, }\StringTok{"San Andres"}\NormalTok{)}

\CommentTok{# replace NA with 0}
\NormalTok{dat2[}\KeywordTok{is.na}\NormalTok{(dat2)] <-}\StringTok{ }\DecValTok{0}

\CommentTok{# convert pre-computed incidence in data.frame into incidence object }
\CommentTok{# grouped by locations}
\NormalTok{i.group <-}\StringTok{ }\KeywordTok{as.incidence}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dat2[, }\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{], }\DataTypeTok{dates =}\NormalTok{ dat2}\OperatorTok{$}\NormalTok{date)}

\CommentTok{# pool incidence across two locations}
\NormalTok{i.pooled <-}\StringTok{ }\KeywordTok{pool}\NormalTok{(i.group)}
\KeywordTok{plot}\NormalTok{(i.group, }\DataTypeTok{border =} \StringTok{"white"}\NormalTok{)  }\OperatorTok{+}\StringTok{ }\NormalTok{my_theme }\OperatorTok{+}\StringTok{ }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.7}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(i.pooled, }\DataTypeTok{border =} \StringTok{"white"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{my_theme}
\end{Highlighting}
\end{Shaded}


\begin{figure}[h!]
\centering
	\includegraphics[width=\textwidth]{figures/incidence-curve2-1.pdf}
	\caption{\label{fig:incidence-curve2}(A) stratified and (B) pooled daily incidence plots
of ZVD in Colombia, September 2015 to January 2016.}
\end{figure}


As shown in Figure \ref{fig:incidence-curve2}B, the pooled daily incidence in Colombia shows approximately exponential phases before and after the epidemic peak.
Therefore, we fit two log-linear regression models around the peak to characterize the epidemic dynamics of ZVD in Colombia.
Such models can be separately fitted to the two phases of the epicurve of \texttt{i.pooled} using the \texttt{fit()} function, which, however, requires us to know what date should be used to split the epicurve in two phases (see the argument \texttt{split} in the \texttt{fit()} function).
Without any knowledge on the splitting date, we can turn to the \texttt{fit\_optim\_split()} function to look for the optimal splitting date (i.e.~the one maximizing the average fit of both models) and then fit two log-linear regression models before and after the optimal splitting date.


\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{'magrittr'}\NormalTok{)}

\NormalTok{fos <-}\StringTok{ }\KeywordTok{fit_optim_split}\NormalTok{(i.pooled)}
\NormalTok{fos}\OperatorTok{$}\NormalTok{split}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2015-11-15"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fos}\OperatorTok{$}\NormalTok{fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <list of incidence_fit objects>
## 
## attr(x, 'locations'): list of vectors with the locations of each incidence_fit object
## 
## 'before'
## 'after'
## 
## $model: regression of log-incidence over time
## 
## $info: list containing the following items:
##   $r (daily growth rate):
##      before       after 
##  0.06659200 -0.04813045 
## 
##   $r.conf (confidence interval):
##              2.5 %      97.5 %
## before  0.05869968  0.07448432
## after  -0.05440018 -0.04186071
## 
##   $doubling (doubling time in days):
##   before 
## 10.40887 
## 
##   $doubling.conf (confidence interval):
##           2.5 %   97.5 %
## before 9.305948 11.80836
## 
##   $halving (halving time in days):
##    after 
## 14.40143 
## 
##   $halving.conf (confidence interval):
##          2.5 %   97.5 %
## after 12.74163 16.55842
## 
##   $pred: data.frame of incidence predictions (129 rows, 6 columns)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(i.pooled, }\DataTypeTok{border =} \StringTok{"white"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{add_incidence_fit}\NormalTok{(fos}\OperatorTok{$}\NormalTok{fit) }\OperatorTok{+}
\StringTok{  }\NormalTok{my_theme}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h!]
\centering
	\includegraphics[width=\textwidth]{figures/incidence-fit-1.pdf}
	\caption{\label{fig:incidence-fit}Fit two log-linear regression models, before and after the optimal splitting date.}
\end{figure}

The returned object \texttt{fos} is a list with 4 components.
The \texttt{\$split} component suggests that the optimal splitting date is 2015-11-15.
The \texttt{\$fit} component is an \textbf{incidence\_fit\_list} containing two \textbf{incidence\_fit} objects named `before' and `after'.
These each contain the information extracted from the fitted log-linear regression models.
Printing the \texttt{\$fit} component shows a daily growth rate \textit{r} of 0.067 and its 95\% confidence interval (CI) ({[}0.059, 0.074{]}), and a doubling time of 10.4 days (95\% CI, {[}9.31, 11.8{]}) during the first phase, and a daily decreasing rate \textit{r} of -0.048 (95\% CI, {[}-0.054, -0.042{]}), and a halving time of 14.4 days (95\% CI, {[}12.7, 16.6{]}) during the second.

The predictions and their 95\% CIs from the two \textbf{incidence\_fit} objects, `before' and `after', can be added to the existing incidence plot of \texttt{i.pooled} using the piping-friendly function \texttt{add\_incidence\_fit()}.
As shown in Figure \ref{fig:incidence-fit}, based on visual comparison of models and data, these two log-linear regression models provide a decent approximation for the actual dynamics of the epidemic (adjusted $R^2$ = 0.83 and 0.77 for the increasing and decreasing phases, respectively).

\section*{Conclusion} 

This article has described the package \textit{incidence} and its features---which include three lightweight data classes and utilities for data manipulation, plotting, and modeling.
We have shown that an \textbf{incidence} object can flexibly be defined at different datetime intervals with any number of stratifications and be subset by groups or dates. 
The most important aspects of this package are use-ability and interoperability.
For both field epidemiologists and academic modellers, the data received are often in the form of line-lists where each row represents a single case.
We have shown that these data can easily be converted to an \textbf{incidence} object and then plotted with sensible defaults in two lines of code.

We have additionally shown that because the data are aggregated into a matrix of counts, it becomes simple to perform operations related to peak-finding, model-fitting, and exportation (e.g. using \texttt{as.data.frame()}) into different formats.
Thus, because it has built-in tools for aggregation, visualisation, and model fitting, the \textit{incidence} package is ideal for rapid generation of reports and estimates in outbreak response situations where time is a critical factor.


\section*{Software availability}
\textit{incidence} available from: \url{https://www.repidemicsconsortium.org/incidence}\\
Code to reproduce all figures can be found by running \texttt{demo("incidence-demo", package = "incidence")} from the R console with the incidence package installed.\\
Source code available from: \url{https://github.com/reconhub/incidence}\\
Archived source code as at time of publication: \url{https://doi.org/10.5281/zenodo.2540217}\\
Software license: MIT

\section*{Data availability}

\textit{Underlying data}\\
Datasets used in the worked examples are from the \href{https://cran.r-project.org/web/packages/outbreaks/index.html}{\textit{outbreaks}} package:\\
\texttt{ebola\_sim\_clean}: \url{https://github.com/reconhub/outbreaks/blob/master/data/ebola_sim_clean.RData}\\
\texttt{zika\_girardot\_2015}: \url{https://github.com/reconhub/outbreaks/blob/master/data/zika_girardot_2015.RData}\\
\texttt{zika\_sanandres\_2015}: \url{https://github.com/reconhub/outbreaks/blob/master/data/zika_sanandres_2015.RData}

\section*{Author information}

TJ, ZNK, JC, JP, and JS developed the package.\\
TJ, ZNK, and JC wrote the manuscript.\\
All authors approved the final version of the manuscript.

\section*{Competing interests}

No competing interests were disclosed.

\section*{Grant information}

The authors acknowledge financial support from the Global Challenges Research Fund (GCRF) for the project ‘RECAP – research capacity building and knowledge generation to support preparedness and response to humanitarian crises and epidemics’ managed through RCUK and ESRC (ES/P010873/1), from the UK Public Health Rapid Support Team, which is funded by the United Kingdom Department of Health and Social Care, and from the National Institute for Health Research - Health Protection Research Unit for Modelling Methodology.

\section*{Acknowledgments}

We would like to thank Michael H\"ohle for discussion about the caveats for \texttt{estimate\_peak()}, the R developer community for constantly improving our working environment, \href{https://www.github.com}{github} for hosting our project, \href{https://travis-ci.org/}{travis}, \href{https://www.appveyor.com/}{appveyor} and \href{https://codecov.io/}{codecov} for providing free continuous integration resources, and the \href{http://www.repidemicsconsortium.org/}{RECON community}. 


{\small\bibliographystyle{unsrtnat}
\bibliography{incidence-references}}


\end{document}
